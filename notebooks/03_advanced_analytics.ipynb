{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Notebook 03: Advanced Analytics\n",
                "\n",
                "Covers: Anomaly detection, ASI calculation, inclusion risk, forecasting with Prophet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "from pathlib import Path\n",
                "project_root = Path.cwd().parent\n",
                "if str(project_root) not in sys.path: sys.path.insert(0, str(project_root))\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import plotly.express as px\n",
                "\n",
                "from src import config\n",
                "from src.preprocessing import load_processed, save_processed\n",
                "from src.metrics import calculate_asi, detect_inclusion_risk, calculate_saturation_status, identify_imbalanced_districts, rank_service_load, detect_volatility_spikes, calculate_all_metrics\n",
                "from src.models import AnomalyDetector, EnrolmentForecaster, detect_anomalies_in_dataframe\n",
                "from src.viz import plot_asi_choropleth, plot_anomaly_scatter, plot_forecast, plot_inclusion_risk_map, generate_summary_table\n",
                "\n",
                "print('Imports loaded')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load processed data\n",
                "df = load_processed(config.MERGED_DATA_FILE)\n",
                "print(f'Loaded {len(df):,} rows, {df[\"district\"].nunique()} districts')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Anomaly Detection with Isolation Forest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Detect anomalies\n",
                "features = [f for f in config.ANOMALY_FEATURES if f in df.columns]\n",
                "print(f'Using features: {features}')\n",
                "\n",
                "df = detect_anomalies_in_dataframe(df, features)\n",
                "print(f'\\nAnomalies detected: {df[\"is_anomaly\"].sum():,} ({df[\"is_anomaly\"].mean()*100:.1f}%)')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Anomaly scatter plot\n",
                "fig = plot_anomaly_scatter(df, config.METRIC_ENROLMENT_TOTAL, config.METRIC_TOTAL_UPDATES)\n",
                "fig.write_html(config.FIGURES_DIR / 'anomaly_scatter.html')\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Districts with anomalies\n",
                "anomaly_districts = df[df['is_anomaly'] == 1].groupby(['state', 'district']).size().reset_index(name='anomaly_count')\n",
                "anomaly_districts = anomaly_districts.sort_values('anomaly_count', ascending=False)\n",
                "print('Top 20 districts by anomaly count:')\n",
                "display(anomaly_districts.head(20))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. ASI (Aadhaar Stress Index) Calculation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate ASI for all districts\n",
                "asi_scores = calculate_asi(df, district=None, include_national=True)\n",
                "\n",
                "# Convert to dataframe\n",
                "asi_df = pd.DataFrame(list(asi_scores.items()), columns=['district', 'asi_score'])\n",
                "asi_df = asi_df.sort_values('asi_score', ascending=False)\n",
                "\n",
                "print(f'National ASI: {asi_scores.get(\"NATIONAL\", 0):.1f}')\n",
                "print(f'\\nTop 20 districts by ASI:')\n",
                "display(asi_df[asi_df['district'] != 'NATIONAL'].head(20))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add ASI to main dataframe\n",
                "df = df.merge(asi_df[asi_df['district'] != 'NATIONAL'], on='district', how='left')\n",
                "df['asi_score'] = df['asi_score'].fillna(50)  # Default for missing\n",
                "\n",
                "# ASI distribution\n",
                "fig = px.histogram(asi_df[asi_df['district'] != 'NATIONAL'], x='asi_score', nbins=30, title='ASI Score Distribution')\n",
                "fig.add_vline(x=60, line_dash='dash', line_color='red', annotation_text='Threshold=60')\n",
                "fig.update_layout(template='plotly_white')\n",
                "fig.write_html(config.FIGURES_DIR / 'asi_distribution.html')\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ASI choropleth/bar chart\n",
                "fig = plot_asi_choropleth(df)\n",
                "fig.write_html(config.FIGURES_DIR / 'asi_choropleth.html')\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Inclusion Risk Detection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Detect inclusion risks\n",
                "df = detect_inclusion_risk(df)\n",
                "\n",
                "risk_summary = df.groupby(['state', 'district'])['inclusion_risk'].any().reset_index()\n",
                "at_risk_count = risk_summary['inclusion_risk'].sum()\n",
                "print(f'Districts at inclusion risk: {at_risk_count} ({at_risk_count/len(risk_summary)*100:.1f}%)')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Risk breakdown\n",
                "risk_cols = ['risk_low_velocity', 'risk_high_ratio_low_growth', 'risk_zero_enrolments']\n",
                "for col in risk_cols:\n",
                "    if col in df.columns:\n",
                "        count = df.groupby('district')[col].any().sum()\n",
                "        print(f'{col}: {count} districts')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Inclusion risk map\n",
                "fig = plot_inclusion_risk_map(df)\n",
                "fig.write_html(config.FIGURES_DIR / 'inclusion_risk.html')\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Saturation and Service Load Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate saturation status\n",
                "df = calculate_saturation_status(df)\n",
                "print('Saturation status distribution:')\n",
                "print(df['saturation_status'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Identify imbalanced districts\n",
                "df = identify_imbalanced_districts(df)\n",
                "print('\\nBalance status distribution:')\n",
                "print(df['balance_status'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Top 20 high-pressure districts\n",
                "high_pressure = rank_service_load(df, top_n=20)\n",
                "print('\\nTop 20 High-Pressure Districts:')\n",
                "display(high_pressure)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Time Series Forecasting with Prophet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare national-level time series\n",
                "daily = df.groupby('date').agg({config.METRIC_ENROLMENT_TOTAL: 'sum', config.METRIC_TOTAL_UPDATES: 'sum'}).reset_index()\n",
                "print(f'Time series: {len(daily)} days')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fit forecaster\n",
                "forecaster = EnrolmentForecaster(horizon=30)\n",
                "forecaster.fit(daily, target_col=config.METRIC_ENROLMENT_TOTAL)\n",
                "\n",
                "# Generate forecast\n",
                "forecast = forecaster.forecast(periods=30)\n",
                "print(f'Forecast generated for {len(forecast)} days')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Backtest\n",
                "metrics = forecaster.backtest(daily, test_days=30)\n",
                "print(f'\\nBacktest Results:')\n",
                "print(f'  MAPE: {metrics[\"mape\"]:.2f}%')\n",
                "print(f'  RMSE: {metrics[\"rmse\"]:,.0f}')\n",
                "print(f'  MAE: {metrics[\"mae\"]:,.0f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot forecast\n",
                "fig = plot_forecast(daily, forecast)\n",
                "fig.write_html(config.FIGURES_DIR / 'enrolment_forecast.html')\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Forecast for updates\n",
                "forecaster_updates = EnrolmentForecaster(horizon=30)\n",
                "forecaster_updates.fit(daily, target_col=config.METRIC_TOTAL_UPDATES)\n",
                "forecast_updates = forecaster_updates.forecast(periods=30)\n",
                "\n",
                "fig = plot_forecast(daily, forecast_updates, title='Total Updates Forecast')\n",
                "fig.write_html(config.FIGURES_DIR / 'updates_forecast.html')\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Save Enhanced Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save with all analytics columns\n",
                "save_processed(df, config.MERGED_DATA_FILE)\n",
                "\n",
                "print('\\nAdvanced Analytics Complete!')\n",
                "print(f'Dataset saved with {len(df.columns)} columns')\n",
                "print(f'\\nNew columns added:')\n",
                "new_cols = ['is_anomaly', 'anomaly_score', 'asi_score', 'inclusion_risk', 'saturation_status', 'balance_status']\n",
                "for c in new_cols:\n",
                "    if c in df.columns:\n",
                "        print(f'  - {c}')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}